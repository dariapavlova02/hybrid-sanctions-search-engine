#!/usr/bin/env python3
"""
Load testing script for AI Service - 50 requests per second
"""

import asyncio
import aiohttp
import time
import json
from typing import List, Dict, Any
from dataclasses import dataclass
from collections import defaultdict
import random
import statistics

@dataclass
class TestResult:
    """Result of a single test request"""
    request_id: int
    start_time: float
    end_time: float
    status_code: int
    response_time: float
    success: bool
    error: str = None
    response_data: dict = None


class LoadTester:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results: List[TestResult] = []
        self.test_data = self._generate_test_data()

    def _generate_test_data(self) -> List[str]:
        """Generate varied test data for more realistic testing"""
        return [
            # Ukrainian names
            "ĞŸĞµÑ‚Ñ€Ğ¾ ĞŸĞ¾Ñ€Ğ¾ÑˆĞµĞ½ĞºĞ¾",
            "Ğ’Ğ¾Ğ»Ğ¾Ğ´Ğ¸Ğ¼Ğ¸Ñ€ Ğ—ĞµĞ»ĞµĞ½ÑÑŒĞºĞ¸Ğ¹",
            "Ğ®Ğ»Ñ–Ñ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞµĞ½ĞºĞ¾",
            "Ğ’Ñ–Ñ‚Ğ°Ğ»Ñ–Ğ¹ ĞšĞ»Ğ¸Ñ‡ĞºĞ¾",
            "Ğ†Ğ³Ğ¾Ñ€ ĞšĞ¾Ğ»Ğ¾Ğ¼Ğ¾Ğ¹ÑÑŒĞºĞ¸Ğ¹",
            "Ğ Ñ–Ğ½Ğ°Ñ‚ ĞÑ…Ğ¼ĞµÑ‚Ğ¾Ğ²",
            "ĞŸĞ°Ğ²Ğ»Ğ¾ Ğ¤ÑƒĞºÑ",
            "Ğ’Ğ°Ğ´Ğ¸Ğ¼ ĞĞ¾Ğ²Ğ¸Ğ½ÑÑŒĞºĞ¸Ğ¹",
            "Ğ”Ğ¼Ğ¸Ñ‚Ñ€Ğ¾ Ğ¤Ñ–Ñ€Ñ‚Ğ°Ñˆ",
            "Ğ¡ĞµÑ€Ğ³Ñ–Ğ¹ Ğ¢Ñ–Ğ³Ñ–Ğ¿ĞºĞ¾",

            # Russian names
            "Ğ’Ğ»Ğ°Ğ´Ğ¸Ğ¼Ğ¸Ñ€ ĞŸÑƒÑ‚Ğ¸Ğ½",
            "Ğ¡ĞµÑ€Ğ³ĞµĞ¹ Ğ›Ğ°Ğ²Ñ€Ğ¾Ğ²",
            "ĞœĞ¸Ñ…Ğ°Ğ¸Ğ» ĞœĞ¸ÑˆÑƒÑÑ‚Ğ¸Ğ½",
            "Ğ”Ğ¼Ğ¸Ñ‚Ñ€Ğ¸Ğ¹ ĞœĞµĞ´Ğ²ĞµĞ´ĞµĞ²",
            "ĞĞ»ĞµĞºÑĞµĞ¹ ĞĞ°Ğ²Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹",

            # Complex cases with context
            "ĞŸĞ»Ğ°Ñ‚ĞµĞ¶ Ğ¾Ñ‚ ĞŸĞµÑ‚Ñ€Ğ° ĞŸĞ¾Ñ€Ğ¾ÑˆĞµĞ½ĞºĞ¾",
            "ĞĞ¿Ğ»Ğ°Ñ‚Ğ° ÑƒÑĞ»ÑƒĞ³ Ğ˜Ğ²Ğ°Ğ½Ğ¾Ğ² Ğ˜Ğ²Ğ°Ğ½ Ğ˜Ğ²Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‡",
            "ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´ Ğ¾Ñ‚ ĞĞĞ Ğ Ğ¾Ğ³Ğ° Ğ¸ ĞšĞ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ´Ğ»Ñ ĞŸĞµÑ‚Ñ€Ğ¾Ğ²Ğ°",
            "Ğ¡Ğ¿Ğ»Ğ°Ñ‚Ğ° Ğ¿Ğ¾ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñƒ Ğ²Ñ–Ğ´ Ğ‘ÑƒĞ»Ğ°Ñ‚ ĞœĞ°ĞºÑĞ¸Ğ¼ Ğ„Ğ²Ğ³ĞµĞ½Ğ¾Ğ²Ğ¸Ñ‡",
            "ĞĞ±Ğ¾Ğ½ Ğ¿Ğ»Ğ°Ñ‚Ğ° Ğ·Ğ° Ñ‚ĞµĞ»ĞµĞºĞ¾Ğ¼ÑƒĞ½Ñ–ĞºĞ°Ñ†Ñ–Ğ¹Ğ½Ñ– Ğ¿Ğ¾ÑĞ»ÑƒĞ³Ğ¸, Ğ¨ĞµĞ²Ñ‡ĞµĞ½ĞºĞ¾",

            # With IDs
            "ĞŸĞ°Ğ²Ğ»Ğ¾Ğ²Ğ° Ğ”Ğ°Ñ€Ñ–Ñ Ğ†ĞŸĞ 782611846337",
            "Ğ†Ğ²Ğ°Ğ½Ğ¾Ğ² Ğ†Ğ²Ğ°Ğ½ Ğ†ĞŸĞ 1234567890",
            "ĞŸĞµÑ‚Ñ€ĞµĞ½ĞºĞ¾ ĞŸĞµÑ‚Ñ€Ğ¾ Ğ„Ğ”Ğ ĞŸĞĞ£ 12345678",

            # Misspelled names (for vector search)
            "ĞŸĞ¾Ñ€Ğ¾ÑˆĞµĞ½Ğº ĞŸĞµÑ‚Ñ€Ğ¾",
            "Ğ—ĞµĞ»ĞµĞ½ÑĞºĞ¹ Ğ’Ğ»Ğ°Ğ´Ğ¸Ğ¼Ğ¸Ñ€",
            "Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞµĞ½Ğº Ğ®Ğ»Ğ¸Ñ",

            # English names
            "John Smith",
            "Mary Johnson",
            "Robert Williams Jr.",

            # Mixed scripts
            "Sergey Ğ›Ğ°Ğ²Ñ€Ğ¾Ğ²",
            "Vladimir ĞŸÑƒÑ‚Ñ–Ğ½",
            "Oleksandr Smith",

            # Organizations
            "Ğ¢ĞĞ’ ĞŸÑ€Ğ¸Ğ²Ğ°Ñ‚Ğ±Ğ°Ğ½Ğº",
            "ĞĞĞ Ğ“Ğ°Ğ·Ğ¿Ñ€Ğ¾Ğ¼",
            "LLC Microsoft Ukraine",
            "ĞĞ¢ Ğ£ĞºÑ€Ğ½Ğ°Ñ„Ñ‚Ğ°",

            # Edge cases
            ".",
            "123",
            "   ",
            "Ğ†Ğ²Ğ°Ğ½",
            "Ğ.Ğ‘.",
            "Ñ„Ğ¾Ğ½ Ğ´ĞµÑ€ Ğ›ÑĞ¹ĞµĞ½",
            "Ğ´'ĞÑ€Ñ‚Ğ°Ğ½ÑŒÑĞ½",
            "Ğ'Ğ‘Ñ€Ğ°Ğ¹ĞµĞ½",
            "ĞœĞ°Ğº-Ğ”Ğ¾Ğ½Ğ°Ğ»ÑŒĞ´",

            # Long texts
            "ĞŸĞ»Ğ°Ñ‚Ñ–Ğ¶ Ğ·Ğ° ĞºĞ¾Ğ¼ÑƒĞ½Ğ°Ğ»ÑŒĞ½Ñ– Ğ¿Ğ¾ÑĞ»ÑƒĞ³Ğ¸ Ğ²Ñ–Ğ´ Ğ†Ğ²Ğ°Ğ½Ğ¾Ğ²Ğ° Ğ†Ğ²Ğ°Ğ½Ğ° Ğ†Ğ²Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‡Ğ° Ğ·Ğ° Ğ»Ğ¸ÑÑ‚Ğ¾Ğ¿Ğ°Ğ´ 2024 Ñ€Ğ¾ĞºÑƒ Ğ·Ğ³Ñ–Ğ´Ğ½Ğ¾ Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñƒ â„–123456",
            "Payment from John Smith for consulting services according to invoice INV-2024-001 dated November 15, 2024",

            # Multiple persons
            "ĞŸĞµÑ‚Ñ€Ğ¾ ĞŸĞ¾Ñ€Ğ¾ÑˆĞµĞ½ĞºĞ¾ Ñ‚Ğ° Ğ®Ğ»Ñ–Ñ Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞµĞ½ĞºĞ¾",
            "Ğ†Ğ²Ğ°Ğ½Ğ¾Ğ², ĞŸĞµÑ‚Ñ€Ğ¾Ğ² Ñ– Ğ¡Ğ¸Ğ´Ğ¾Ñ€Ğ¾Ğ²",
            "ĞÑ‚ ĞœĞ°Ñ€Ñ–Ñ— Ñ‚Ğ° Ğ†Ğ²Ğ°Ğ½Ğ° ĞŸĞµÑ‚Ñ€ĞµĞ½ĞºÑ–Ğ²",
        ]

    async def send_request(self, session: aiohttp.ClientSession, request_id: int, text: str) -> TestResult:
        """Send a single request to the API"""
        start_time = time.time()

        payload = {
            "text": text,
            "language": "auto",
            "enable_search": True,
            "enable_variants": False,
            "enable_embeddings": False
        }

        try:
            async with session.post(
                f"{self.base_url}/api/v1/process",
                json=payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # Convert to ms

                response_data = await response.json()

                return TestResult(
                    request_id=request_id,
                    start_time=start_time,
                    end_time=end_time,
                    status_code=response.status,
                    response_time=response_time,
                    success=response.status == 200,
                    response_data=response_data
                )

        except asyncio.TimeoutError:
            end_time = time.time()
            return TestResult(
                request_id=request_id,
                start_time=start_time,
                end_time=end_time,
                status_code=0,
                response_time=(end_time - start_time) * 1000,
                success=False,
                error="Timeout"
            )

        except Exception as e:
            end_time = time.time()
            return TestResult(
                request_id=request_id,
                start_time=start_time,
                end_time=end_time,
                status_code=0,
                response_time=(end_time - start_time) * 1000,
                success=False,
                error=str(e)
            )

    async def run_batch(self, session: aiohttp.ClientSession, batch_size: int, batch_id: int) -> List[TestResult]:
        """Run a batch of requests concurrently"""
        tasks = []
        for i in range(batch_size):
            request_id = batch_id * batch_size + i
            text = random.choice(self.test_data)
            tasks.append(self.send_request(session, request_id, text))

        return await asyncio.gather(*tasks)

    async def run_load_test(self, target_rps: int = 50, duration_seconds: int = 10):
        """Run the load test at target RPS for specified duration"""
        print(f"ğŸš€ Starting load test: {target_rps} RPS for {duration_seconds} seconds")
        print(f"ğŸ“Š Total requests to send: {target_rps * duration_seconds}")
        print("-" * 60)

        connector = aiohttp.TCPConnector(
            limit=100,  # Connection pool size
            limit_per_host=100
        )

        async with aiohttp.ClientSession(connector=connector) as session:
            # Warm up with a single request
            print("ğŸ”¥ Warming up...")
            await self.send_request(session, 0, "warm up request")

            print(f"ğŸ“ˆ Starting main test at {target_rps} RPS...")
            start_time = time.time()

            # Calculate batch parameters
            batch_size = target_rps  # Send target_rps requests each second
            total_batches = duration_seconds

            for batch_id in range(total_batches):
                batch_start = time.time()

                # Send batch
                batch_results = await self.run_batch(session, batch_size, batch_id)
                self.results.extend(batch_results)

                # Calculate how long to wait to maintain RPS
                batch_duration = time.time() - batch_start
                wait_time = max(0, 1.0 - batch_duration)  # Wait remainder of the second

                # Progress update
                completed = (batch_id + 1) * batch_size
                print(f"  Batch {batch_id + 1}/{total_batches}: {completed} requests sent, "
                      f"batch took {batch_duration:.2f}s, waiting {wait_time:.2f}s")

                if wait_time > 0:
                    await asyncio.sleep(wait_time)

            total_duration = time.time() - start_time
            actual_rps = len(self.results) / total_duration

        print("-" * 60)
        print(f"âœ… Load test completed!")
        print(f"â±ï¸  Total duration: {total_duration:.2f} seconds")
        print(f"ğŸ“Š Actual RPS: {actual_rps:.2f}")

        self.print_statistics()

    def print_statistics(self):
        """Print detailed statistics of the test results"""
        if not self.results:
            print("âŒ No results to analyze")
            return

        # Calculate statistics
        successful = [r for r in self.results if r.success]
        failed = [r for r in self.results if not r.success]

        response_times = [r.response_time for r in successful]

        print("\n" + "=" * 60)
        print("ğŸ“Š TEST RESULTS SUMMARY")
        print("=" * 60)

        print(f"\nâœ… Success Rate: {len(successful)}/{len(self.results)} "
              f"({len(successful)/len(self.results)*100:.1f}%)")
        print(f"âŒ Failed: {len(failed)}")

        if response_times:
            print(f"\nâ±ï¸  Response Time Statistics (successful requests):")
            print(f"   Min:     {min(response_times):.2f} ms")
            print(f"   Max:     {max(response_times):.2f} ms")
            print(f"   Mean:    {statistics.mean(response_times):.2f} ms")
            print(f"   Median:  {statistics.median(response_times):.2f} ms")
            if len(response_times) > 1:
                print(f"   StdDev:  {statistics.stdev(response_times):.2f} ms")

            # Calculate percentiles
            sorted_times = sorted(response_times)
            p50 = sorted_times[len(sorted_times) * 50 // 100]
            p90 = sorted_times[len(sorted_times) * 90 // 100]
            p95 = sorted_times[len(sorted_times) * 95 // 100]
            p99 = sorted_times[len(sorted_times) * 99 // 100] if len(sorted_times) > 100 else sorted_times[-1]

            print(f"\nğŸ“ˆ Percentiles:")
            print(f"   50th (p50): {p50:.2f} ms")
            print(f"   90th (p90): {p90:.2f} ms")
            print(f"   95th (p95): {p95:.2f} ms")
            print(f"   99th (p99): {p99:.2f} ms")

        # Error analysis
        if failed:
            print(f"\nâŒ Error Analysis:")
            error_counts = defaultdict(int)
            for r in failed:
                error_counts[r.error or f"HTTP {r.status_code}"] += 1

            for error, count in sorted(error_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"   {error}: {count}")

        # Status code distribution
        print(f"\nğŸ”¢ Status Code Distribution:")
        status_counts = defaultdict(int)
        for r in self.results:
            status_counts[r.status_code] += 1

        for status, count in sorted(status_counts.items()):
            print(f"   {status}: {count}")

        # Response time distribution
        if response_times:
            print(f"\nğŸ“Š Response Time Distribution:")
            buckets = [0, 10, 25, 50, 100, 200, 500, 1000, 2000, 5000, float('inf')]
            bucket_counts = defaultdict(int)

            for rt in response_times:
                for i in range(len(buckets) - 1):
                    if buckets[i] <= rt < buckets[i + 1]:
                        bucket_counts[f"{buckets[i]}-{buckets[i+1]}ms"] += 1
                        break

            for bucket, count in sorted(bucket_counts.items(), key=lambda x: float(x[0].split('-')[0])):
                percentage = count / len(response_times) * 100
                bar = 'â–ˆ' * int(percentage / 2)
                print(f"   {bucket:>15}: {bar} {count} ({percentage:.1f}%)")


async def main():
    """Main function to run the load test"""
    tester = LoadTester()

    # Run load test at 50 RPS for 10 seconds
    await tester.run_load_test(target_rps=50, duration_seconds=10)

    print("\n" + "=" * 60)
    print("ğŸ’¡ RECOMMENDATIONS:")
    print("=" * 60)

    # Analyze and provide recommendations
    if tester.results:
        successful = [r for r in tester.results if r.success]
        success_rate = len(successful) / len(tester.results)

        if success_rate < 0.95:
            print("âš ï¸  Success rate is below 95%. Consider:")
            print("   â€¢ Increasing server resources (CPU/Memory)")
            print("   â€¢ Optimizing database queries")
            print("   â€¢ Implementing caching")
            print("   â€¢ Scaling horizontally (more instances)")

        response_times = [r.response_time for r in successful] if successful else []
        if response_times and statistics.mean(response_times) > 1000:
            print("âš ï¸  Average response time exceeds 1 second. Consider:")
            print("   â€¢ Profiling the application to find bottlenecks")
            print("   â€¢ Optimizing normalization algorithms")
            print("   â€¢ Implementing async processing where possible")
            print("   â€¢ Using connection pooling")

        if success_rate >= 0.95 and response_times and statistics.mean(response_times) < 500:
            print("âœ… Server is handling 50 RPS well!")
            print("   â€¢ Consider increasing RPS to find the limit")
            print("   â€¢ Monitor resource usage during peak loads")
            print("   â€¢ Set up alerts for performance degradation")


if __name__ == "__main__":
    print("ğŸ”§ AI Service Load Testing Tool")
    print("================================")
    asyncio.run(main())