#!/usr/bin/env python3
"""
Ð¢ÐµÑÑ‚ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… ÐºÐµÐ¹ÑÐ¾Ð².
"""

import asyncio
import json
import time
import sys
sys.path.insert(0, '.')
sys.path.insert(0, 'src')

async def test_real_cases():
    """Ð¢ÐµÑÑ‚ Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¸Ð¼ÐµÐ½Ð°Ð¼Ð¸ Ð¸ Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¼Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸."""
    print("ðŸŽ¯ PRODUCTION REAL CASES TEST")
    print("="*50)

    # Initialize orchestrator
    try:
        from ai_service.core.orchestrator_factory import OrchestratorFactory
        orchestrator = await OrchestratorFactory.create_production_orchestrator()
        print("âœ… Orchestrator initialized")
    except Exception as e:
        print(f"âŒ Failed to initialize orchestrator: {e}")
        return

    # Test cases with expected risk levels
    test_cases = [
        {
            "name": "ÐšÐ¾Ð²Ð°Ð»ÐµÐ½ÐºÐ¾ ÐžÐ»ÐµÐºÑÐ°Ð½Ð´Ñ€Ð° Ð¡ÐµÑ€Ð³Ñ–Ñ—Ð²Ð½Ð°",
            "expected_risk": "low",
            "notes": "Full Ukrainian female name with patronymic"
        },
        {
            "name": "Ð¡ÐµÑ€Ð³Ñ–Ð¹ ÐžÐ»Ñ–Ð¹Ð½Ð¸Ðº",
            "expected_risk": "medium",
            "notes": "Ukrainian male name without patronymic"
        },
        {
            "name": "LiudÐ¼ÑƒlÐ° UliÐ°nÐ¾vÐ°",
            "expected_risk": "low",
            "notes": "Mixed script (Latin + Cyrillic) homoglyph attack"
        }
    ]

    print(f"\nðŸ§ª Testing {len(test_cases)} real production cases...")

    for i, test_case in enumerate(test_cases, 1):
        name = test_case["name"]
        expected_risk = test_case["expected_risk"]
        notes = test_case["notes"]

        print(f"\n{i}. Testing: '{name}'")
        print(f"   Expected: {expected_risk} risk")
        print(f"   Notes: {notes}")

        try:
            start_time = time.time()
            result = await orchestrator.process(name)
            processing_time = (time.time() - start_time) * 1000

            # Extract key results
            normalized = result.normalized_text
            language = result.language
            lang_conf = result.language_confidence
            success = result.success

            print(f"   â±ï¸  Processing time: {processing_time:.1f}ms")
            print(f"   ðŸ“ Normalized: '{normalized}'")
            print(f"   ðŸŒ Language: {language} ({lang_conf:.3f})")
            print(f"   âœ… Success: {success}")

            # Check signals
            if result.signals:
                # Handle both dict and object access
                if hasattr(result.signals, 'persons'):
                    persons = result.signals.persons or []
                elif isinstance(result.signals, dict):
                    persons = result.signals.get('persons', [])
                else:
                    persons = []

                print(f"   ðŸ‘¥ Persons found: {len(persons)}")

                for j, person in enumerate(persons[:2], 1):
                    if isinstance(person, dict):
                        core = person.get('core', 'N/A')
                        conf = person.get('confidence', 0)
                        evidence = person.get('evidence', [])
                    else:
                        core = getattr(person, 'core', 'N/A')
                        conf = getattr(person, 'confidence', 0)
                        evidence = getattr(person, 'evidence', [])

                    print(f"     {j}. Core: {core}")
                    print(f"        Confidence: {conf:.3f}")
                    if evidence:
                        print(f"        Evidence: {evidence[:3]}")  # Show first 3

            # Check trace for debugging
            if result.trace:
                print(f"   ðŸ” Token traces: {len(result.trace)}")
                for trace in result.trace[:3]:  # Show first 3 traces
                    token = trace.token if hasattr(trace, 'token') else 'N/A'
                    role = trace.role if hasattr(trace, 'role') else 'N/A'
                    rule = trace.rule if hasattr(trace, 'rule') else 'N/A'
                    print(f"     '{token}' -> {role} ({rule})")

            # Risk assessment
            print(f"   ðŸŽ¯ Expected risk: {expected_risk}")

            # Check if we can detect homoglyph attacks
            if "mixed script" in notes.lower():
                has_mixed_chars = any(ord(c) > 127 for c in name) and any(ord(c) <= 127 for c in name)
                if has_mixed_chars:
                    print(f"   âš ï¸  Mixed script detected - potential homoglyph attack")

        except Exception as e:
            print(f"   âŒ Processing failed: {e}")
            import traceback
            traceback.print_exc()

    print(f"\n{'='*50}")
    print("ðŸŽ‰ REAL PRODUCTION CASES TEST COMPLETED")
    print("="*50)

    print("ðŸ“Š Key observations:")
    print("â€¢ Full Ukrainian names with patronymics should normalize correctly")
    print("â€¢ Mixed script names (homoglyph attacks) should be detected")
    print("â€¢ Processing time should be reasonable (< 1000ms)")
    print("â€¢ Language detection should work for mixed scripts")
    print("â€¢ Token role classification should handle complex cases")

if __name__ == "__main__":
    asyncio.run(test_real_cases())