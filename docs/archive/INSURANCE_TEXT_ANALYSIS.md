# Insurance Text Processing Analysis

## Problem Summary

The API was incorrectly processing insurance payment text, returning wrong normalized results:

**Input text:**
```
"–°—Ç—Ä–∞—Ö–æ–≤–∏–π –ø–ª–∞—Ç—ñ–∂ –∑–∞ –ø–æ–ª—ñ—Å –û–°–¶–ü–í EPcode 232483013 –≤—ñ–¥ 20.09.2025 –•–∞–º—ñ–Ω –í–ª–∞–¥–∏—Å–ª–∞–≤ –Ü–≥–æ—Ä–æ–≤–∏—á —ñ–ø–Ω 3731301153 –ê—Ä—Å–µ–Ω–∞–ª AG*232483013 33908322"
```

**Expected result:** Should extract and normalize "–•–∞–º—ñ–Ω –í–ª–∞–¥–∏—Å–ª–∞–≤ –Ü–≥–æ—Ä–æ–≤–∏—á" (name + patronymic)

**Actual API result:**
```json
{
  "normalized_text": "–ü–æ–ª—ñ—Å –°—Ç—Ä–∞—Ö–æ–≤–∏–π",
  "tokens": ["–ü–æ–ª—ñ—Å", "–°—Ç—Ä–∞—Ö–æ–≤–∏–π", ""]
}
```

## Root Cause Analysis

### 1. Insurance Context Not Recognized

**Problem:** Insurance terms were being classified as personal names:
- "–°—Ç—Ä–∞—Ö–æ–≤–∏–π" (insurance) ‚Üí classified as `given` name
- "–ø–æ–ª—ñ—Å" (policy) ‚Üí classified as `surname`

**Solution:** Added insurance terms to lexicons:
- `data/lexicons/payment_context.txt`
- `src/ai_service/data/dicts/stopwords.py`
- `src/ai_service/layers/variants/templates/lexicon.py`

**Terms added:** —Å—Ç—Ä–∞—Ö–æ–≤–∏–π, –ø–æ–ª—ñ—Å, –û–°–¶–ü–í, –û–°–ê–ì–û, –ö–ê–°–ö–û, —Å—Ç—Ä–∞—Ö—É–≤–∞–Ω–Ω—è, etc.

### 2. API vs Factory Implementation Discrepancy

**Key Finding:** Factory normalization works correctly but API uses different path.

**Factory test result (correct):**
```
Factory result: '232483013 –•–∞–º—ñ–Ω –í–ª–∞–¥–∏—Å–ª–∞–≤ –ê—Ä—Å–µ–Ω–∞–ª –Ü–≥–æ—Ä–æ–≤–∏—á'
Factory tokens: ['232483013', '–•–∞–º—ñ–Ω', '–í–ª–∞–¥–∏—Å–ª–∞–≤', '–ê—Ä—Å–µ–Ω–∞–ª', '–Ü–≥–æ—Ä–æ–≤–∏—á']
```

**API result (incorrect):**
```json
{
  "normalized_text": "–ü–æ–ª—ñ—Å –°—Ç—Ä–∞—Ö–æ–≤–∏–π",
  "tokens": ["–ü–æ–ª—ñ—Å", "–°—Ç—Ä–∞—Ö–æ–≤–∏–π", ""]
}
```

### 3. Normalization Path Analysis

The API configuration shows:
```json
"flags": {
  "normalization_implementation": "factory",
  "use_factory_normalizer": true
}
```

But the trace shows FSM role tagger being used:
```json
{
  "token": "–í–ª–∞–¥–∏—Å–ª–∞–≤",
  "role": "unknown",
  "notes": "FSM role tagger: token '–í–ª–∞–¥–∏—Å–ª–∞–≤' -> unknown (reason: fallback_unknown)"
}
```

**Hypothesis:** The unified_orchestrator is using FSM role tagger service instead of factory role classification, leading to different results.

## Files Modified

### 1. Insurance Context Addition
- `data/lexicons/payment_context.txt` - Added insurance terms
- `src/ai_service/data/dicts/stopwords.py` - Added to STOP_ALL
- `src/ai_service/layers/variants/templates/lexicon.py` - Added to PAYMENT_CONTEXT and STOPWORDS_*

### 2. Payment Word Filtering
- Added "—Å–ø–ª–∞—Ç–∞" to all payment context lexicons to prevent misclassification as given name

## Commits

1. `fix(normalization): add "—Å–ø–ª–∞—Ç–∞" to payment context filters` - Fixed "–°–ø–ª–∞—Ç–∞" being classified as given name
2. `fix(normalization): add insurance context filtering` - Added comprehensive insurance terms

## Next Steps

To fully resolve the API issue:

1. **Investigate unified_orchestrator normalization path** - Determine why API uses FSM role tagger instead of factory
2. **Ensure API flags properly route to factory** - Fix the configuration so factory normalization is actually used
3. **Test end-to-end pipeline** - Verify that insurance terms are properly filtered and names correctly extracted

## Test Cases

To verify the fix:

```bash
curl -X POST 'http://95.217.84.234:8000/process' -H 'Content-Type: application/json' -d '{
  "text": "–°—Ç—Ä–∞—Ö–æ–≤–∏–π –ø–ª–∞—Ç—ñ–∂ –∑–∞ –ø–æ–ª—ñ—Å –û–°–¶–ü–í EPcode 232483013 –≤—ñ–¥ 20.09.2025 –•–∞–º—ñ–Ω –í–ª–∞–¥–∏—Å–ª–∞–≤ –Ü–≥–æ—Ä–æ–≤–∏—á —ñ–ø–Ω 3731301153 –ê—Ä—Å–µ–Ω–∞–ª AG*232483013 33908322"
}'
```

**Expected result after fix:**
- Insurance terms should be filtered out
- "–•–∞–º—ñ–Ω –í–ª–∞–¥–∏—Å–ª–∞–≤ –Ü–≥–æ—Ä–æ–≤–∏—á" should be properly normalized
- –Ü–ù–ù "3731301153" should be extracted in signals

## Status

‚úÖ **Fixed:** Insurance context filtering
‚úÖ **Fixed:** Payment word classification
üîÑ **In Progress:** API normalization path consistency