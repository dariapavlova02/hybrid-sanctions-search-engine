#!/usr/bin/env python3
"""
Full Deployment Pipeline
========================

–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Elasticsearch.

–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:
1. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã (sanctioned_persons.json, sanctioned_companies.json, terrorism_black_list.json)
2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç AC patterns –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤
3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç vector embeddings –∏–∑ AC patterns
4. –°–æ–∑–¥–∞—ë—Ç –∏–Ω–¥–µ–∫—Å—ã –≤ Elasticsearch
5. –ó–∞–≥—Ä—É–∂–∞–µ—Ç AC patterns –≤ ES
6. –ó–∞–≥—Ä—É–∂–∞–µ—Ç vectors –≤ ES
7. –î–µ–ª–∞–µ—Ç warmup queries
8. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç

Usage:
    # –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª (–ª–æ–∫–∞–ª—å–Ω–æ)
    python scripts/full_deployment_pipeline.py

    # –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª (–Ω–∞ production)
    python scripts/full_deployment_pipeline.py --es-host elasticsearch:9200

    # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å)
    python scripts/full_deployment_pipeline.py --skip-preparation

    # –¢–æ–ª—å–∫–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (–±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ ES)
    python scripts/full_deployment_pipeline.py --prepare-only
"""

import argparse
import asyncio
import json
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))


def print_header(text: str):
    """Print formatted header"""
    print(f"\n{'='*70}")
    print(f"  {text}")
    print(f"{'='*70}\n")


def print_step(step_num: int, total_steps: int, text: str):
    """Print step indicator"""
    print(f"\nüîπ Step {step_num}/{total_steps}: {text}")
    print("-" * 70)


def check_source_files() -> Dict[str, Path]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    print_step(1, 7, "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")

    data_dir = project_root / "src" / "ai_service" / "data"

    files = {
        "persons": data_dir / "sanctioned_persons.json",
        "companies": data_dir / "sanctioned_companies.json",
        "terrorism": data_dir / "terrorism_black_list.json"
    }

    all_exist = True
    for name, filepath in files.items():
        if filepath.exists():
            size_mb = filepath.stat().st_size / (1024 * 1024)
            print(f"‚úÖ {name:12} {filepath.name:45} ({size_mb:.1f} MB)")
        else:
            print(f"‚ùå {name:12} {filepath.name:45} –û–¢–°–£–¢–°–¢–í–£–ï–¢!")
            all_exist = False

    if not all_exist:
        print("\n‚ùå –ù–µ –≤—Å–µ –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã!")
        print("   –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª—ã —Å–∞–Ω–∫—Ü–∏–π –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ src/ai_service/data/")
        sys.exit(1)

    return files


def prepare_sanctions_data(max_patterns: int = 200, skip_vectors: bool = False) -> Tuple[Path, Optional[Path]]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: AC patterns + vectors"""
    print_step(2, 7, "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ AC patterns –∏ –≤–µ–∫—Ç–æ—Ä–æ–≤")

    output_dir = project_root / "output" / "sanctions"
    output_dir.mkdir(parents=True, exist_ok=True)

    # –ê—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è prepare_sanctions_data.py
    cmd = [
        sys.executable,
        str(project_root / "scripts" / "prepare_sanctions_data.py"),
        "--output-dir", str(output_dir),
        "--max-patterns", str(max_patterns)
    ]

    if skip_vectors:
        cmd.append("--skip-vectors")

    print(f"üìù –ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")
    print()

    # –ó–∞–ø—É—Å–∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏
    result = subprocess.run(cmd, capture_output=False, text=True)

    if result.returncode != 0:
        print("\n‚ùå –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π!")
        sys.exit(1)

    # –ù–∞—Ö–æ–¥–∏–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    patterns_files = sorted(output_dir.glob("ac_patterns_*.json"), reverse=True)
    vectors_files = sorted(output_dir.glob("vectors_*.json"), reverse=True)

    if not patterns_files:
        print("\n‚ùå AC patterns —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        sys.exit(1)

    patterns_file = patterns_files[0]
    vectors_file = vectors_files[0] if vectors_files else None

    print(f"\n‚úÖ AC patterns: {patterns_file.name}")
    if vectors_file:
        print(f"‚úÖ Vectors: {vectors_file.name}")
    else:
        print(f"‚ö†Ô∏è  Vectors –Ω–µ —Å–æ–∑–¥–∞–Ω—ã (–ø—Ä–æ–ø—É—â–µ–Ω—ã)")

    return patterns_file, vectors_file


def deploy_to_elasticsearch(
    es_host: str,
    patterns_file: Path,
    vectors_file: Optional[Path],
    index_prefix: str = "sanctions"
) -> bool:
    """–†–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ Elasticsearch"""
    print_step(3, 7, "–†–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ Elasticsearch")

    cmd = [
        sys.executable,
        str(project_root / "scripts" / "deploy_to_elasticsearch.py"),
        "--es-host", es_host,
        "--index-prefix", index_prefix,
        "--patterns-file", str(patterns_file)
    ]

    if vectors_file:
        cmd.extend([
            "--vectors-file", str(vectors_file),
            "--create-vector-indices"
        ])

    print(f"üìù –ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")
    print()

    result = subprocess.run(cmd, capture_output=False, text=True)

    if result.returncode != 0:
        print("\n‚ùå –†–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–æ–π!")
        return False

    print("\n‚úÖ –†–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
    return True


def verify_deployment(es_host: str, index_prefix: str = "sanctions") -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è"""
    print_step(4, 7, "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è")

    import aiohttp

    async def check():
        ac_index = f"{index_prefix}_ac_patterns"
        vector_index = f"{index_prefix}_vectors"

        try:
            async with aiohttp.ClientSession() as session:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ AC patterns
                async with session.get(f"http://{es_host}/{ac_index}/_count") as response:
                    if response.status == 200:
                        data = await response.json()
                        ac_count = data.get('count', 0)
                        print(f"‚úÖ {ac_index:30} {ac_count:,} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                    else:
                        print(f"‚ùå {ac_index:30} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                        return False

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ vectors
                async with session.get(f"http://{es_host}/{vector_index}/_count") as response:
                    if response.status == 200:
                        data = await response.json()
                        vector_count = data.get('count', 0)
                        if vector_count > 0:
                            print(f"‚úÖ {vector_index:30} {vector_count:,} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                        else:
                            print(f"‚ö†Ô∏è  {vector_index:30} –ø—É—Å—Ç–æ–π (–≤–µ–∫—Ç–æ—Ä—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã)")
                    else:
                        print(f"‚ö†Ô∏è  {vector_index:30} –Ω–µ –Ω–∞–π–¥–µ–Ω")

                return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False

    return asyncio.run(check())


def print_summary(
    start_time: float,
    patterns_file: Path,
    vectors_file: Optional[Path],
    es_host: str,
    index_prefix: str
):
    """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å–≤–æ–¥–∫–∏"""
    print_header("‚úÖ –†–ê–ó–í–Å–†–¢–´–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")

    elapsed = time.time() - start_time
    elapsed_min = int(elapsed // 60)
    elapsed_sec = int(elapsed % 60)

    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_min}m {elapsed_sec}s")
    print()
    print("üì¶ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print(f"   ‚Ä¢ {patterns_file.name}")
    if vectors_file:
        print(f"   ‚Ä¢ {vectors_file.name}")
    print()
    print("üìç Elasticsearch:")
    print(f"   ‚Ä¢ Host: {es_host}")
    print(f"   ‚Ä¢ –ò–Ω–¥–µ–∫—Å—ã:")
    print(f"     - {index_prefix}_ac_patterns")
    print(f"     - {index_prefix}_vectors")
    print()
    print("üß™ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å:")
    print(f"   curl -X POST http://{es_host.replace('elasticsearch:9200', 'localhost:8000')}/process \\")
    print(f"     -H 'Content-Type: application/json' \\")
    print(f"     -d '{{\"text\": \"–î–∞—Ä—å—è –ü–ê–≤–ª–æ–≤–∞ –ò–ù–ù 2839403975\"}}' | jq")
    print()


def main():
    parser = argparse.ArgumentParser(
        description="–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    parser.add_argument(
        "--es-host",
        default="localhost:9200",
        help="Elasticsearch host (default: localhost:9200)"
    )

    parser.add_argument(
        "--index-prefix",
        default="sanctions",
        help="–ü—Ä–µ—Ñ–∏–∫—Å –∏–º—ë–Ω –∏–Ω–¥–µ–∫—Å–æ–≤ (default: sanctions)"
    )

    parser.add_argument(
        "--max-patterns",
        type=int,
        default=200,
        help="–ú–∞–∫—Å–∏–º—É–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ entity (default: 200)"
    )

    parser.add_argument(
        "--skip-preparation",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã)"
    )

    parser.add_argument(
        "--skip-vectors",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–µ–∫—Ç–æ—Ä–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ)"
    )

    parser.add_argument(
        "--prepare-only",
        action="store_true",
        help="–¢–æ–ª—å–∫–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ ES)"
    )

    args = parser.parse_args()

    start_time = time.time()

    print_header("üöÄ –ü–û–õ–ù–´–ô –¶–ò–ö–õ –†–ê–ó–í–Å–†–¢–´–í–ê–ù–ò–Ø –°–ê–ù–ö–¶–ò–û–ù–ù–´–• –î–ê–ù–ù–´–•")
    print(f"üìç Elasticsearch: {args.es_host}")
    print(f"üì¶ Index prefix: {args.index_prefix}")
    print(f"‚öôÔ∏è  Max patterns: {args.max_patterns}")

    try:
        # Step 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        check_source_files()

        # Step 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if args.skip_preparation:
            print_step(2, 7, "–ü–æ–∏—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤")
            output_dir = project_root / "output" / "sanctions"
            patterns_files = sorted(output_dir.glob("ac_patterns_*.json"), reverse=True)
            vectors_files = sorted(output_dir.glob("vectors_*.json"), reverse=True)

            if not patterns_files:
                print("‚ùå AC patterns —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω! –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–∑ --skip-preparation")
                sys.exit(1)

            patterns_file = patterns_files[0]
            vectors_file = vectors_files[0] if vectors_files else None

            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π: {patterns_file.name}")
            if vectors_file:
                print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π: {vectors_file.name}")
        else:
            patterns_file, vectors_file = prepare_sanctions_data(
                max_patterns=args.max_patterns,
                skip_vectors=args.skip_vectors
            )

        # Step 3: –†–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –Ω–µ prepare-only)
        if args.prepare_only:
            print("\n‚ÑπÔ∏è  –†–µ–∂–∏–º prepare-only: —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")
            print(f"\nüì¶ –§–∞–π–ª—ã –≥–æ—Ç–æ–≤—ã –≤: {patterns_file.parent}")
            print(f"\nüí° –î–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
            print(f"   python scripts/deploy_to_elasticsearch.py \\")
            print(f"     --es-host {args.es_host} \\")
            print(f"     --patterns-file {patterns_file} \\")
            if vectors_file:
                print(f"     --vectors-file {vectors_file} \\")
                print(f"     --create-vector-indices")
            sys.exit(0)

        success = deploy_to_elasticsearch(
            args.es_host,
            patterns_file,
            vectors_file,
            args.index_prefix
        )

        if not success:
            sys.exit(1)

        # Step 4: –ü—Ä–æ–≤–µ—Ä–∫–∞
        verify_deployment(args.es_host, args.index_prefix)

        # Summary
        print_summary(start_time, patterns_file, vectors_file, args.es_host, args.index_prefix)

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(130)
    except Exception as e:
        print(f"\n\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
